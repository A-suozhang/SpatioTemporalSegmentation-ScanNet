# Copyright (c) 2020 NVIDIA CORPORATION.
# Copyright (c) 2018-2020 Chris Choy (chrischoy@ai.stanford.edu).
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies
# of the Software, and to permit persons to whom the Software is furnished to do
# so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# Please cite "4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural
# Networks", CVPR'19 (https://arxiv.org/abs/1904.08755) if you use any part
# of the code.
import os
import random
import numpy as np
import glob

try:
    import h5py
except:
    print("Install h5py with `pip install h5py`")
import subprocess

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import MinkowskiEngine as ME
import MinkowskiEngine.MinkowskiOps as me

import sys
# sys.path.append('/home/zhaotianchen/project/point-transformer/pt-cls/model')
from models.pct_voxel_utils import TDLayer, TULayer, PTBlock

class MinkowskiTransformerNet(ME.MinkowskiNetwork):
    def __init__(self, in_channel, out_channel, num_class, final_dim=96, dimension=3):

        ME.MinkowskiNetwork.__init__(self, dimension)
        # The normal channel for Modelnet is 3, for scannet is 6, for scanobjnn is 0
        normal_channel = 3

        self.dims = np.array([32, 64, 128, 256])
        # self.dims = np.array([32, 32, 64, 64])
        # self.dims = np.array([64, 128, 256])

        # self.neighbor_ks = [16, 16, 16, 16, 16]
        self.neighbor_ks = np.array([8, 8, 16, 16, 16])

        # self.dims = self.dims // 2
        self.final_dim = final_dim

        stem_dim =  self.dims[0]
        # in_channel = normal_channel+3 # normal ch + xyz
        self.normal_channel = normal_channel

        # pixel size 1
        self.stem1 = nn.Sequential(
            ME.MinkowskiConvolution(in_channel, stem_dim, kernel_size=3, dimension=3),
            ME.MinkowskiBatchNorm(stem_dim),
            ME.MinkowskiReLU(),
        )

        # does the spatial downsampling
        # pixel size 2
        self.stem2 = nn.Sequential(
            ME.MinkowskiConvolution(stem_dim, stem_dim, kernel_size=3, dimension=3, stride=2),
            ME.MinkowskiBatchNorm(stem_dim),
            ME.MinkowskiReLU(),
        )

        # pixel size 2
        self.PTBlock1 = PTBlock(in_dim=self.dims[0], hidden_dim = self.dims[0], n_sample=self.neighbor_ks[0])
        self.TDLayer1 = TDLayer(input_dim=self.dims[0], out_dim=self.dims[1]) # strided conv

        # pixel size 4
        self.PTBlock2 = PTBlock(in_dim=self.dims[1], hidden_dim = self.dims[1], n_sample=self.neighbor_ks[1])
        self.TDLayer2 = TDLayer(input_dim=self.dims[1], out_dim=self.dims[2])

        # pixel size 8
        self.PTBlock3 = PTBlock(in_dim=self.dims[2],hidden_dim = self.dims[2], n_sample=self.neighbor_ks[2])
        self.TDLayer3 = TDLayer(input_dim=self.dims[2], out_dim=self.dims[3])

        # pixel size 16
        self.PTBlock4 = PTBlock(in_dim=self.dims[3], hidden_dim = self.dims[3], n_sample=self.neighbor_ks[3])

        # pixel size 8
        self.TULayer5 = TULayer(input_a_dim=self.dims[3], input_b_dim = self.dims[2], out_dim=self.dims[3]) # out: 256//2 + 128 = 256
        # self.PTBlock5 = PTBlock(in_dim=self.dims[3]//2+self.dims[2], hidden_dim = self.dims[3], n_sample=self.neighbor_ks[3]) # out: 256
        self.PTBlock5 = PTBlock(in_dim=self.dims[3], hidden_dim = self.dims[3], n_sample=self.neighbor_ks[3]) # out: 256

        # pixel size 4
        self.TULayer6 = TULayer(input_a_dim=self.dims[3], input_b_dim = self.dims[1], out_dim=self.dims[2]) # out: 256//2 + 64 = 192
        # self.PTBlock6 = PTBlock(in_dim=self.dims[3]//2+self.dims[1], hidden_dim=self.dims[2], n_sample=self.neighbor_ks[2]) # out: 128
        self.PTBlock6 = PTBlock(in_dim=self.dims[2], hidden_dim=self.dims[2], n_sample=self.neighbor_ks[2]) # out: 128

        # pixel size 2
        self.TULayer7 = TULayer(input_a_dim=self.dims[2], input_b_dim = self.dims[0], out_dim=self.dims[1]) # 128 // 2 + 32 = 96
        # self.PTBlock7 = PTBlock(in_dim=self.dims[2]//2+self.dims[0], hidden_dim=self.dims[1], n_sample=self.neighbor_ks[1]) # out: 64
        self.PTBlock7 = PTBlock(in_dim=self.dims[1], hidden_dim=self.dims[1], n_sample=self.neighbor_ks[1]) # out: 64

        # pixel size 1
        self.TULayer8 = TULayer(input_a_dim=self.dims[1], input_b_dim = self.dims[0], out_dim=self.dims[0]) # 64 // 2 + 32
        # self.PTBlock8 = PTBlock(in_dim=self.dims[1]//2+self.dims[0], hidden_dim=self.dims[0], n_sample=self.neighbor_ks[1])  # 32
        self.PTBlock8 = PTBlock(in_dim=self.dims[0], hidden_dim=self.dims[0], n_sample=self.neighbor_ks[1])  # 32

        # self.global_avg_pool = ME.MinkowskiGlobalAvgPooling()
        self.final_conv = ME.MinkowskiConvolutionTranspose(self.dims[1], self.final_dim, kernel_size=2, stride=2, dimension=3)
        self.fc = ME.MinkowskiLinear(self.final_dim+self.dims[0], out_channel)

    def forward(self, in_field: ME.TensorField):


        import time
        start = time.perf_counter()

        # x = in_field.sparse() # when using tensorfield into model, if use vxoek , no need
        x = in_field

        # print('total {} voxels'.format(x.shape[0]))

        x0 = self.stem1(x)
        x = self.stem2(x0)
        x1, attn_1 = self.PTBlock1(x)

        x = self.TDLayer1(x1)
        x2, attn_2 = self.PTBlock2(x)

        x = self.TDLayer2(x2)
        x3, attn_3 = self.PTBlock3(x)

        x = self.TDLayer3(x3)
        x4, attn_4 = self.PTBlock4(x)

        x = self.TULayer5(x4, x3)
        x5, attn_5 = self.PTBlock5(x)

        x = self.TULayer6(x5, x2)
        x6, attn_6 = self.PTBlock6(x)

        x = self.TULayer7(x6, x1)
        x7, attn_7 = self.PTBlock7(x)

        # final big PTBlock
        # x = self.TULayer8(x7, x0)
        # x8, attn_8 = self.PTBlock8(x)
        # x = self.fc(x8)

        x = self.final_conv(x7)
        x = self.fc(me.cat(x0,x))

        end = time.time()

        #print(f"forward time: {end-start} s")
        # print('PT ratio:{}'.format((pt2 - pt1) / (pt2 - pt0)))

        return x




